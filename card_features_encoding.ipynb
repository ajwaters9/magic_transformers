{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hO2kSfCIZ1ko"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahRriGKDbIPk",
        "outputId": "b89ed8d9-70f0-4548-fbc8-bc1c370040fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Import card data sourced from scryfall.com\n",
        "!wget -O oracle-cards.json https://data.scryfall.io/oracle-cards/oracle-cards-20240521210234.json\n",
        "# Import card list sourced from 17lands.com\n",
        "!wget -O cards_list.csv https://17lands-public.s3.amazonaws.com/analysis_data/cards/cards.csv\n",
        "\n",
        "df = pd.read_json('oracle-cards.json')\n",
        "cl = pd.read_csv('cards_list.csv')\n",
        "\n",
        "# Map NaN's in 'arena_id' from scryfall data to correct values from 17lands data\n",
        "df_ss = df[['name', 'arena_id']]\n",
        "cl_merge = cl.merge(df_ss, how='left', left_on='name',right_on='name')\n",
        "na_lookup = cl_merge.loc[cl_merge['arena_id'].isna()][['name','id']]\n",
        "na_lookup = na_lookup.set_index('name')\n",
        "na_map = {k:v.values[0] for k,v in na_lookup.iterrows()}\n",
        "mapped_ids = df['name'].map(na_map)\n",
        "df['arena_id'] = df['arena_id'].fillna(mapped_ids)\n",
        "\n",
        "\n",
        "# Card text cleaning functions\n",
        "def replace_self_reference(card_text, card_name):\n",
        "    return card_text.replace(card_name, 'cardname')\n",
        "def replace_newline(card):\n",
        "    return card.replace('\\n', ' ')\n",
        "def is_multiface(card):\n",
        "    if card in ['transform', 'adventure', 'modal_dfc', 'split']: return 1\n",
        "    else: return 0\n",
        "\n",
        "# Drop all cards not in Arena\n",
        "df.dropna(subset=['arena_id'], inplace = True)\n",
        "# Filter out all non-engligh printings\n",
        "df = df.loc[df['lang'] == 'en']\n",
        "# Filter out all token cards\n",
        "df = df.loc[df['layout'] != 'token']\n",
        "# Standardize text for cards that refer to themselves\n",
        "df['oracle_text'] = df.apply(lambda row: replace_self_reference(str(row['oracle_text']), row['name']), axis=1)\n",
        "# Add column to indicate multi-modal cards\n",
        "df['is_multiface'] = df.apply(lambda row: is_multiface(row['layout']), axis=1)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Extract multi-faced card text\n",
        "def expand_dual_faced_cards(df):\n",
        "    # Prepare a list to collect new rows\n",
        "    new_rows = []\n",
        "    # Track indices to potentially drop later\n",
        "    updated_indices = []\n",
        "    # Iterate through each row in the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        if isinstance(row['card_faces'], list):\n",
        "            combined_text = []\n",
        "            combined_power = []\n",
        "            combined_toughness = []\n",
        "            # Process each face of the card\n",
        "            for face in row['card_faces']:\n",
        "                # Create a new row dictionary starting from the current row's data\n",
        "                new_row = row.to_dict()\n",
        "                # Update this new row with data from the current face\n",
        "                new_row.update(face)\n",
        "                # Remove the 'card_faces' key as it's no longer needed in the new row\n",
        "                new_row.pop('card_faces', None)\n",
        "                # Add the new row to the list\n",
        "                new_rows.append(new_row)\n",
        "                cleaned_text = replace_self_reference(new_row['oracle_text'], new_row['name'])\n",
        "                combined_text.append(cleaned_text)\n",
        "                combined_power.append(new_row['power'])\n",
        "                combined_toughness.append(new_row['toughness'])\n",
        "            # Populate oracle text with both cards' text\n",
        "            df.loc[index, 'oracle_text'] = combined_text[0] + ' // ' + combined_text[1]\n",
        "            # Populate power and toughness with values from the front card face\n",
        "            df.loc[index, 'power'] = combined_power[0]\n",
        "            df.loc[index, 'toughness'] = combined_toughness[0]\n",
        "            # Mark the index to drop the original row later\n",
        "            updated_indices.append(index)\n",
        "    return df\n",
        "\n",
        "df = expand_dual_faced_cards(df)\n",
        "\n",
        "# Filter out Alchemy cards\n",
        "alchemy_idx = []\n",
        "for idx, cardname in enumerate(df['name']):\n",
        "    if cardname[:2] == 'A-':\n",
        "        alchemy_idx.append(idx)\n",
        "df.drop(alchemy_idx, inplace=True)\n",
        "\n",
        "COLUMNS_TO_KEEP = ['arena_id','name', 'layout','mana_cost', 'cmc', 'type_line','oracle_text', 'power',\n",
        "                    'toughness', 'color_identity','keywords', 'set', 'rarity',\n",
        "                    'is_multiface']\n",
        "\n",
        "df['arena_id'] = df['arena_id'].astype(int)\n",
        "df = df[COLUMNS_TO_KEEP]\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "def get_secondary_types(type_line):\n",
        "    if len(type_line.split(' — ')) <= 1:\n",
        "        return np.nan\n",
        "    else:\n",
        "        return type_line.split(' — ')[1]\n",
        "\n",
        "\n",
        "df['type_line'] = df.apply(lambda row: row['type_line'].split(' // ')[0], axis=1)\n",
        "df['primary_type'] = df.apply(lambda row: row['type_line'].split(' — ')[0], axis=1)\n",
        "df['secondary_type'] = df.apply(lambda row: get_secondary_types(row['type_line']), axis=1)\n",
        "df['color_identity'] = df.apply(lambda row: ''.join(row['color_identity']), axis=1)\n",
        "\n",
        "# Indicator variable for primary types\n",
        "df['is_legend']   = df['primary_type'].apply(lambda x: 'Legendary' in x)\n",
        "df['is_creature'] = df['primary_type'].apply(lambda x: 'Creature' in x)\n",
        "df['is_instant']  = df['primary_type'].apply(lambda x: 'Instant' in x)\n",
        "df['is_sorcery']  = df['primary_type'].apply(lambda x: 'Sorcery' in x)\n",
        "df['is_enchant']  = df['primary_type'].apply(lambda x: 'Enchantment' in x)\n",
        "df['is_artifact'] = df['primary_type'].apply(lambda x: 'Artifact' in x)\n",
        "df['is_planeswalker'] = df['primary_type'].apply(lambda x: 'Planeswalker' in x)\n",
        "df['is_land'] =  df['primary_type'].apply(lambda x: 'Land' in x)\n",
        "# df['is_snow'] =  df['primary_type'].apply(lambda x: 'Snow' in x)\n",
        "# df['is_battle'] = df['primary_type'].apply(lambda x: 'Battle' in x)\n",
        "# df['is_horror'] = df['primary_type'].apply(lambda x: 'Horror' in x)\n",
        "# df['is_tribal'] = df['primary_type'].apply(lambda x: 'Tribal' in x)\n",
        "# df['is_basic'] = df['primary_type'].apply(lambda x: 'Basic' in x)\n",
        "\n",
        "# Indicator variables for color identities\n",
        "df['is_w'] = df['color_identity'].apply(lambda x: 'W' in x)\n",
        "df['is_u'] = df['color_identity'].apply(lambda x: 'U' in x)\n",
        "df['is_b'] = df['color_identity'].apply(lambda x: 'B' in x)\n",
        "df['is_r'] = df['color_identity'].apply(lambda x: 'R' in x)\n",
        "df['is_g'] = df['color_identity'].apply(lambda x: 'G' in x)\n",
        "\n",
        "# Extract all keywords\n",
        "keywords = []\n",
        "def get_keywords(card):\n",
        "    for x in card:\n",
        "        keywords.append(x)\n",
        "for card in df['keywords']:\n",
        "    get_keywords(card)\n",
        "keywords_list = list(set(keywords))\n",
        "\n",
        "# Prepare one-hot dataframe for keywords\n",
        "keyword_dict = {}\n",
        "for keyword in keywords_list:\n",
        "    keyword_dict[keyword] = [keyword in x for x in df['keywords']]\n",
        "df_keywords = pd.DataFrame(keyword_dict)\n",
        "\n",
        "# Set variables for evergreen keywords only\n",
        "evergreen_keywords = ['Deathtouch','Defender','Double strike', 'Enchant', 'Equip', 'First strike',\n",
        "                      'Flash', 'Flying', 'Haste', 'Hexproof', 'Indestructible', 'Lifelink', 'Menace',\n",
        "                      'Protection', 'Reach', 'Trample', 'Vigilance']\n",
        "\n",
        "df_evergreen = df_keywords[evergreen_keywords]\n",
        "df_set_keywords = df_keywords.drop(columns=evergreen_keywords, axis=1)\n",
        "df_set_keywords['set_keyword'] = (df_set_keywords != 0).any(axis=1)\n",
        "df_keywords = df_evergreen.merge(df_set_keywords['set_keyword'], left_index=True, right_index=True)\n",
        "df = df.join(df_keywords)\n",
        "\n",
        "\n",
        "# Set a variable to iindicate double pips in mana cost\n",
        "def has_double_pip(cost_string):\n",
        "    # regex for any repeated colors in mana cost, like {W}{W}\n",
        "    matches = re.findall(r'\\{([^}]+)\\}', cost_string)\n",
        "    return any(matches.count(x) > 1 for x in set(matches))\n",
        "\n",
        "df['mana_cost'] = df['mana_cost'].astype('str')\n",
        "df['double_pip'] = df['mana_cost'].apply(has_double_pip)\n",
        "\n",
        "# Set a variable to indicate a special layout (e.g. adventure, saga, etc.)\n",
        "df['special_layout'] = df['layout'] != 'normal'\n",
        "\n",
        "# Create new dataframe of relevant columns\n",
        "tab_data = df.drop(['mana_cost', 'type_line', 'oracle_text','color_identity', 'set', 'keywords','primary_type','secondary_type', 'layout'], axis=1)\n",
        "\n",
        "# Set power/toughness of non-creature cards to -2 for one-hot encoding\n",
        "tab_data['power'] = tab_data['toughness'].fillna(-2)\n",
        "tab_data['toughness'] = tab_data['toughness'].fillna(-2)\n",
        "# Set special/variable power/toughness to -1 for one-hot encoding\n",
        "tab_data['power'] = pd.to_numeric(tab_data['power'], errors='coerce').fillna(-1).astype(int)\n",
        "tab_data['toughness'] = pd.to_numeric(tab_data['toughness'], errors='coerce').fillna(-1).astype(int)\n",
        "# Clip power/toughness/cmc to 5\n",
        "tab_data['cmc'] = tab_data['cmc'].clip(upper=5)\n",
        "tab_data['power'] = tab_data['power'].clip(upper=5)\n",
        "tab_data['toughness'] = tab_data['toughness'].clip(upper=5)\n",
        "# One-hot encode cmc, power, toughness, and rarity\n",
        "tab_data = pd.get_dummies(tab_data, columns=['cmc', 'power', 'toughness', 'rarity'])\n",
        "\n",
        "# Reindex using arena_id\n",
        "tab_data = tab_data.set_index('arena_id')\n",
        "# Convert to numeric\n",
        "# tab_data = tab_data.astype(float)\n",
        "# Save to file\n",
        "tab_data.to_parquet('card_features_reduced.parquet')\n",
        "# Save oracle text to file for later use\n",
        "df[['name','arena_id','oracle_text']].to_parquet('oracle_text.parquet')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "python310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
